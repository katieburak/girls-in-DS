---
title: "UBC Science Fair"
subtitle: "Department of Statistics"
format: revealjs
editor: visual
theme: [solarized, themer.scss]
---

## 

::: {style="text-align: center;"}
<h1>Department of Statistics</h1>

<img src="img/sponsor3.png" alt="Sponsor Image" style="margin-top: 30px; max-width: 80%; height: auto;"/>
:::

## What is Statistics?

-   Statistics is the science of data, focused on collecting, analyzing, interpreting, and presenting information
-   In Statistics, we aim to uncover meaningful patterns and trends from data
-   Used in fields like healthcare, sports, business, and government to make informed decisions
-   In todayâ€™s data-driven world, Statistics help us have a better understanding of the world around us

## Scenarios

::: incremental
-   What makes a sports team successful, and how can we use data to improve performance?
-   How can we forecast the weather and predict natural disasters?
-   How do we determine if a new product or advertisement will be popular with customers?
-   How can we predict housing prices based on factors like location, size, and market trends?
:::

## Classification

-   **Machine learning** is a field where computers learn from data to make decisions and predictions.
-   **Classification** is a type of machine learning, where the goal is to predict a categorical class of an observation given other variables (features). For example:
    -   Classifying an email as "spam" or "not spam"
    -   Classifying a medical test as "positive" or "negative"
    -   Classifying a bank transaction as fraudulent or not

## KNN Classification

-   KNN (K-Nearest Neighbors) is a simple, intuitive classification algorithm.
-   It classifies new data points based on the majority class of their closest neighbors in the training data.
-   Today, we will simulate KNN in a fun and interactive way!

------------------------------------------------------------------------

## Training and Test Sets

When building a machine learning model, typically we start by dividing our data into two sets:

-   

    1)  Training set

-   

    2)  Test set

The **training set** is a subset of our data that is used is to train or teach our model to perform sort of predictive task.

Then, using our **test set**, we can evaluate how well our model performs on unseen data.

## Activity

:::incremental
1.  Setting up the Training Data:
		    
    -   Come and get a coloured sticky note (except for 3 volunteers)
    -   Place the sticky notes on your shirt and stand randomly in the room.
    -   You represent labeled training data!
    
2.  Introduce the "Test Points":
    -   3 students act as unlabeled test data.
    -   Stand in random positions in the room.

3.  Find the Nearest Neighbors:
    -   Help each test student identify their 5 closest neighbors $(k=5)$.
    -   Count the colour of the sticky notes of the 5 nearest neighbours.
    -   Majority Vote: The colour with the most votes is your new classification!
:::
    

## Discussion Time

::: incremental
-   Think about how we classified the unknown data point.
    -   What happens if we use $k=1$?
    -   What if we use $k=25$?
-   What could be the challenges with ties or class imbalances?
:::

------------------------------------------------------------------------

## Real-World Applications

-   KNN can be used in many real-life scenarios such as:
    -   Recommendation systems (e.g., recommending movies based on user preferences)
    -   Image classification (e.g., identifying objects in images)
    -   Medical diagnosis (e.g., classifying diseases based on symptoms)

------------------------------------------------------------------------

## Example

We can perform classifcation using real data and computer code!

```{r}
library(ggplot2)
library(tidyverse)
library(tidymodels)

# Data on cancer tumors
tumors <- read_csv("data/clean-wdbc.data.csv") |>
    mutate(Class = as_factor(Class))

head(tumors)
```


## Example

![](https://datasciencebook.ca/_main_files/figure-html/05-multiknn-3-1.png)



## 

```{r, echo = TRUE}
tumor_recipe <- recipe(Class ~ Perimeter + Concavity, data=tumors) |>
                  step_center(all_predictors()) |>
                  step_scale(all_predictors()) 

tumor_model <- nearest_neighbor(weight_func = "rectangular", neighbors = 3) |>
       set_engine("kknn") |>
       set_mode("classification")

tumor_workflow <- workflow() |>
    add_recipe(tumor_recipe) |>
    add_model(tumor_model)

tumor_fit <- tumor_workflow |>
    fit(data=tumors)

new_obs <- tibble(Perimeter = 0.2, Concavity = 3.3)

predict(tumor_fit, new_obs)
```

## Why Study Statistics?

-   Classification is just one example of the many tasks we can accomplish with statistics and data science.
-   With the power of statistics, we can:
    -   Analyze real-world data
    -   Make predictions
    -   Understand complex systems and phenomena
-   If you're interested in working with real data, solving meaningful problems, and making data-driven decisions, consider studying Statistics or Data Science!

## UBC Girls in Data Science Camp

- Dates: July 7-9, 2025
- Time: 10am-3pm
- Location: UBC Vancouver Campus
- Instructor: Katie Burak (Contact: kburak@stat.ubc.ca)

<div style="display: flex; justify-content: center; align-items: center; gap: 5em;">
  <img src="img/logo.png" alt="Logo" style="height: 200px;">
  <img src="img/qr_code.png" alt="QR Code" style="height: 200px;">
</div>

<div style="display: flex; justify-content: center; align-items: center; gap: 2em;">
<https://forms.gle/i3LsjobEhaBTzCpKA>
</div>

## 

::: {style="display: flex; justify-content: center; align-items: center; height: 100%; font-size: 200px; font-weight: bold;"}
Questions?
:::
